# Application
APP_NAME=DevPort Crawler
APP_VERSION=1.0.0
DEBUG=False

# Database
DATABASE_URL=postgresql://devport:password@localhost:5432/devportdb

# LLM API for Korean summarization
# Use one of the following:
OPENAI_API_KEY=sk-your-openai-api-key-here
# OR
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here
# OR
GEMINI_API_KEY=your-gemini-api-key-here

# Choose provider: "openai", "anthropic", or "gemini"
LLM_PROVIDER=openai

# GitHub API (for trending repos)
GITHUB_TOKEN=ghp_your-github-token-here

# Artificial Analysis API (for LLM rankings)
# Get your API key from https://artificialanalysis.ai/
ARTIFICIAL_ANALYSIS_API_KEY=your-artificial-analysis-api-key-here

# Crawling settings
CRAWL_DELAY_SECONDS=2
MAX_CONCURRENT_REQUESTS=5
USER_AGENT=DevPortCrawler/1.0 (+https://devport.kr)

# Playwright settings
PLAYWRIGHT_HEADLESS=True
PLAYWRIGHT_TIMEOUT=30000

# Deduplication
TITLE_SIMILARITY_THRESHOLD=0.9

# Scoring weights
GITHUB_SOURCE_WEIGHT=2.0
BLOG_SOURCE_WEIGHT=1.0
TIME_DECAY_DAYS=7

# Scoring - Time Decay (Exponential Decay System)
# Controls how quickly article scores decrease over time
SCORE_PLATEAU_DAYS=2       # Days before decay starts (0-2 days: full boost)
SCORE_HALF_LIFE_DAYS=4.0   # Days for score to halve (exponential decay rate)
SCORE_MAX_AGE_DAYS=14      # Articles older than this get zero score

# Filtering thresholds
MIN_REACTIONS_DEVTO=10
MIN_REACTIONS_HASHNODE=5
MIN_STARS_GITHUB=50

# AWS (if deploying to Lambda)
AWS_REGION=us-west-2
AWS_ACCESS_KEY_ID=your-access-key
AWS_SECRET_ACCESS_KEY=your-secret-key

# GCP (if deploying to Cloud Run)
GCP_PROJECT_ID=your-project-id
GCP_REGION=us-central1
